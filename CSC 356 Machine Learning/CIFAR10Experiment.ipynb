{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import tarfile\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted. Check to be sure\n"
     ]
    }
   ],
   "source": [
    "cifarDir = \"cifar10dataset\"\n",
    "tarfile.open(\"cifar-10-python.tar.gz\", \"r:gz\").extractall(cifarDir) # Using tarfile to extract data\n",
    "print(\"Files extracted. Check to be sure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "dict_keys(['batch_label', 'labels', 'data', 'filenames'])\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = [] # Creating the blank lists\n",
    "X\n",
    "# Need to extract all the batches with pickle\n",
    "cifarDirBatches = os.path.join(cifarDir,\"cifar-10-batches-py\")\n",
    "for i in range(1, 6): # data_batch_1 to data_batch_5\n",
    "    f = os.path.join(cifarDirBatches, f\"data_batch_{i}\") # Open each batch iteratively\n",
    "    batch = open(f, \"rb\")\n",
    "    dataDict = pickle.load(batch, encoding = \"latin1\") # load the batch with pickle\n",
    "    xtemp = dataDict[\"data\"] # Create temp var\n",
    "    ytemp = dataDict[\"labels\"]\n",
    "    xtemp = xtemp.reshape(10000, 3072) # reshape to the proper size\n",
    "    ys = np.array(ytemp)\n",
    "    X.append(xtemp) # add to the list\n",
    "    Y.append(ytemp)\n",
    "\n",
    "X_train = np.concatenate(X) # Turn into np arrays for training variables\n",
    "Y_train = np.concatenate(Y)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(dataDict.keys()) # Just to show the various categories there was\n",
    "print(type(X_train))\n",
    "print(type(Y_train))\n",
    "\n",
    "del xtemp, ytemp, X, Y # Delete the temporary variables and the old lists\n",
    "# Some code that helped me when I got stuck: https://stackoverflow.com/questions/37512290/reading-cifar10-dataset-in-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Now that we have the training variables, it's time to get the test dataset!\n",
    "# The data is hidden inside a file called test_batch\n",
    "\n",
    "test_set = os.path.join(cifarDirBatches, \"test_batch\")\n",
    "test_batch = open(test_set, \"rb\")\n",
    "testDict = pickle.load(test_batch, encoding=\"latin1\")\n",
    "X_test = testDict[\"data\"]\n",
    "Y_test = testDict[\"labels\"]\n",
    "X_test = X_test.reshape(10000, 3072)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try to fit them to a model, SVC seems like a good choice!\n",
    "# Be wary, it will take a while! Scikit learn doesn't have cuda support so it's really slow! (It took over half \n",
    "# hour for mine to train)\n",
    "\n",
    "if os.exists(\"SVCCLF.p\"):\n",
    "    svc_clf = pickle.load(open(\"SVCCLF.p\", \"rb\"))\n",
    "else:\n",
    "    svc_clf = SVC()\n",
    "    svc_clf.fit(X_train, Y_train)\n",
    "    print(\"Done fitting!\")\n",
    "    # It worked, let's save the model real quick\n",
    "    pickle.dump(svc_clf, open(\"SVCCLF.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
